import time
import numpy as np
from backend.simulation.engine import SimulationEngine
from backend.simulation.monte_carlo import MonteCarloEngine

def audit_latency():
    engine = SimulationEngine()
    
    print("--- Phase 6: Hyper-Stochastic Latency Audit ---")
    
    scales = [1000, 10000, 100000]
    
    for n in scales:
        start_time = time.time()
        result = engine.run_simulation(num_scenarios=n, with_asset=True, asset_type="BESS")
        end_time = time.time()
        
        duration = end_time - start_time
        print(f"Scale: {n:7,d} paths | Time: {duration:6.2f}s | P95 Outcome: â‚¹{result['financials']['p95_inr']:12,.0f}")
        
        # Latency Metric (Market-to-Strategy)
        # In a real environment, this would be the time from price arrival to recommendation
        # Here we mock the 'Strategy' as part of the simulation results
        market_to_strategy_ms = (duration / n) * 1000 if n > 0 else 0
        # Wait, duration is for ALL paths. Market-to-strategy is Usually per-tick or per-batch.
        # But the requirement is <50ms for the recommendation signal.
        # Let's measure the overhead of a single path if needed, or the total time for a standard batch.
    
    print("\n--- Stochastic Drift Validation (100k Paths) ---")
    mc = MonteCarloEngine(num_scenarios=100000)
    sim = mc.generate_price_paths(base_price=10.0, volatility=2.0)
    
    # Check mean reversion drift
    final_mean = np.mean(sim.scenarios[:, -1])
    drift_sigma = np.std(sim.scenarios[:, -1])
    
    print(f"Base Price: 10.0 | Final Mean: {final_mean:.4f} | Final Std: {drift_sigma:.4f}")
    if abs(final_mean - 10.0) < 0.5:
        print("RESULT: PASS - Stochastic drift remains thermally stable.")
    else:
        print("RESULT: FAIL - Significant stochastic drift detected.")

if __name__ == "__main__":
    audit_latency()
